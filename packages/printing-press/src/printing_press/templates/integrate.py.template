from airflow import DAG
from airflow.sdk import Asset
from pendulum import datetime
from smooth_operators import SmoothK8sOperator, StandardiseCSVOperator

SOURCE_DATASETS = {
{% for system, source in source_assets.items() %}
    "{{ system }}": Asset("{{ source }}"),
{% endfor %}
}
TARGET_DATASET = Asset("{{ target_asset }}")
WORKING_CACHE = "s3://working_bucket/{{ dag_id }}/{{ '{{' }} dag_run.run_id {{ '}}' }}"

with DAG(
    dag_id="{{ dag_id }}",
    start_date=datetime({{ start_date }}),
    schedule="{{ schedule }}",
    catchup=False,
) as dag:
    standardise_tasks = []
    for system, source in SOURCE_DATASETS.items():
        task = StandardiseCSVOperator(
            task_id=f"standardise_{system}_task",
            source_path=source,
            target_path=f"{WORKING_CACHE}/{system}_standardised.csv",
        )
        standardise_tasks.append(task)

    integrate_customers = SmoothK8sOperator(
        task_id="integrate_task",
        image="{{ image }}",
        arguments=[
{% for arg in arguments %}
            "{{ arg }}",
{% endfor %}
        ],
        outlets=[TARGET_DATASET],
    )

    standardise_tasks >> integrate_customers